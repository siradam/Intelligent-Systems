{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D5Hy5Lk7yBJ2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fh0GaSnsy7YU"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "# Build a prediction model for water level at main station\n",
    "\n",
    "# Group: Huynh, Thuc Nhat Truong-Jehad Nasser-Asfynder Hashmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV, TimeSeriesSplit\n",
    "from sklearn.linear_model import LinearRegression, MultiTaskElasticNetCV\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fKWkXQmRxv4q"
   },
   "source": [
    "### Load data\n",
    "\n",
    "First of all, in order to have the data to process and construct a prediction model for this assignment we re-use the pre-processed data which has been provided and re-order the dataframe as following.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i168s3j6IYB9",
    "outputId": "01668630-033a-4f71-8d5c-756162cf2194"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_level</th>\n",
       "      <th>main_flow</th>\n",
       "      <th>a_temp</th>\n",
       "      <th>a_status</th>\n",
       "      <th>a_rain</th>\n",
       "      <th>c_temp</th>\n",
       "      <th>c_status</th>\n",
       "      <th>c_rain</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-01 01:00:00</th>\n",
       "      <td>182.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 02:00:00</th>\n",
       "      <td>182.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 03:00:00</th>\n",
       "      <td>182.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 04:00:00</th>\n",
       "      <td>182.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-01 05:00:00</th>\n",
       "      <td>182.0</td>\n",
       "      <td>7.19</td>\n",
       "      <td>1.7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 19:00:00</th>\n",
       "      <td>255.0</td>\n",
       "      <td>15.90</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 20:00:00</th>\n",
       "      <td>259.0</td>\n",
       "      <td>16.40</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 21:00:00</th>\n",
       "      <td>263.0</td>\n",
       "      <td>16.90</td>\n",
       "      <td>8.9</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>4</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 22:00:00</th>\n",
       "      <td>268.0</td>\n",
       "      <td>17.50</td>\n",
       "      <td>8.7</td>\n",
       "      <td>4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>8.9</td>\n",
       "      <td>3</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2017-12-31 23:00:00</th>\n",
       "      <td>272.0</td>\n",
       "      <td>18.00</td>\n",
       "      <td>8.4</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>8.3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>34833 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     main_level  main_flow  a_temp  a_status  a_rain  c_temp  \\\n",
       "time                                                                           \n",
       "2014-01-01 01:00:00       182.0       7.19     2.6         2     0.0     2.8   \n",
       "2014-01-01 02:00:00       182.0       7.19     2.4         2     0.0     2.5   \n",
       "2014-01-01 03:00:00       182.0       7.19     1.9         2     0.0     1.9   \n",
       "2014-01-01 04:00:00       182.0       7.19     2.0         2     0.0     2.1   \n",
       "2014-01-01 05:00:00       182.0       7.19     1.7         2     0.0     2.1   \n",
       "...                         ...        ...     ...       ...     ...     ...   \n",
       "2017-12-31 19:00:00       255.0      15.90     8.9         4     0.1     9.0   \n",
       "2017-12-31 20:00:00       259.0      16.40     8.9         4     0.0     9.3   \n",
       "2017-12-31 21:00:00       263.0      16.90     8.9         4     0.0     9.2   \n",
       "2017-12-31 22:00:00       268.0      17.50     8.7         4     0.2     8.9   \n",
       "2017-12-31 23:00:00       272.0      18.00     8.4         4     0.6     8.3   \n",
       "\n",
       "                     c_status  c_rain  \n",
       "time                                   \n",
       "2014-01-01 01:00:00         2     0.0  \n",
       "2014-01-01 02:00:00         2     0.0  \n",
       "2014-01-01 03:00:00         2     0.0  \n",
       "2014-01-01 04:00:00         2     0.0  \n",
       "2014-01-01 05:00:00         2     0.0  \n",
       "...                       ...     ...  \n",
       "2017-12-31 19:00:00         4     0.0  \n",
       "2017-12-31 20:00:00         3     0.0  \n",
       "2017-12-31 21:00:00         4     0.0  \n",
       "2017-12-31 22:00:00         3     0.5  \n",
       "2017-12-31 23:00:00         4     1.6  \n",
       "\n",
       "[34833 rows x 8 columns]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv('preprocessed_stations.csv',index_col = 'time')\n",
    "df.reindex(columns=['a_temp','a_status','a_rain','c_temp','c_status','c_rain','main_level','main_flow'])\n",
    "df.dropna(inplace=True)#make sure there will be no NaN value\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "id": "b1xUAzaFFhfD"
   },
   "outputs": [],
   "source": [
    "def create_X_y(df):\n",
    "    \"\"\"\n",
    "\tX has the following format:\n",
    "\tOne week per row\n",
    "\trow == sample\n",
    "\t9 sensor values (including timestamps) * 24 h * 7 days = 1512 entries per sample\n",
    "\n",
    "\t[t_0, w_station_A(t_0), w_station_B(t_0), w_station_C(t_0), \n",
    "\t t_1, w_station_A(t_1), w_station_B(t_1), w_station_C(t_1), \n",
    "\t \n",
    "\t t_N, w_station_A(t_N), w_station_B(t_N), w_station_C(t_N)] \n",
    "\n",
    "\n",
    "\t\"\"\"\n",
    "    timestamps = df.shape[0]\n",
    "    \n",
    "    prediction_timestamps = 24\n",
    "    prediction_step = 3\n",
    "    \n",
    "    timestamps_per_week = 24 * 7\n",
    "    samples = timestamps - timestamps_per_week - prediction_timestamps\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "    for i in range(samples):\n",
    "        X.append(df[i:i+timestamps_per_week].to_numpy().flatten())\n",
    "        y.append(df['main_level'].iloc[i + timestamps_per_week : \n",
    "                                       i + timestamps_per_week + prediction_timestamps : \n",
    "                                           prediction_step])\n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    return X, y\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def get_sample_dataframe(X, index):\n",
    "    \n",
    "    assert 0 <= index <= X.shape[0]\n",
    "    \n",
    "    sample_mat = X[index].reshape((24*7,8))\n",
    "    sample_df = pd.DataFrame(sample_mat[:, 1:], index=sample_mat[:,0])\n",
    "\n",
    "    return sample_df\n",
    "\n",
    "def plot_in_2d(X, title=None):\n",
    "    pca = PCA(n_components=2)\n",
    "    pca.fit(X)\n",
    "    X_2d = pca.transform(X)\n",
    "    plt.scatter(X_2d[:,0], X_2d[:,1])\n",
    "    \n",
    "    if title is not None:\n",
    "        plt.title(title)\n",
    "    plt.show()    \n",
    "    \n",
    "    \n",
    "def rmse(y_pred, y_true):  \n",
    "    return np.sqrt(np.mean((y_pred - y_true)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BX491pVG9k_e",
    "outputId": "98b3646b-2b3e-4235-c722-ed497cb9f72a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Load data in ML representation X, y\n",
    "X, y = create_X_y(df)\n",
    "# X = np.delete(X, slice(0, X.shape[1], 9), axis=1)\n",
    "\n",
    "\n",
    "#Split test set and training set\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.25,random_state=0)\n",
    "#Reduce the dimensions with PCA\n",
    "dim_reducer = PCA(n_components=10).fit(X_train)\n",
    "X_train_actual = X_train.copy()\n",
    "X_train = dim_reducer.transform(X_train)\n",
    "#train and test linear regression model\n",
    "lr_regressor = LinearRegression()\n",
    "lr_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hx3P1KsYKlwC",
    "outputId": "ae0a0a6d-63d8-4621-8568-4802cb8daf00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Linear Regression:  9.974016856744601\n"
     ]
    }
   ],
   "source": [
    "#get Mean Square Error >>> Loss \n",
    "y_predict = lr_regressor.predict(dim_reducer.transform(X_test))\n",
    "print('Loss for Linear Regression: ', mean_squared_error(y_true=y_test, y_pred = y_predict, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VmlNhcGlOdS1",
    "outputId": "4b790c88-1ea5-4ad7-ef68-31ca92e81dc2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiTaskElasticNetCV()"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_net_regressor = MultiTaskElasticNetCV()#this is used for parallel prcoessing\n",
    "elastic_net_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRniKb9wSbzb",
    "outputId": "4e091b8f-d52d-461b-c465-2c88de6dd083"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss for Elastic Net:  7.920131472283702\n"
     ]
    }
   ],
   "source": [
    "y_pred = lr_regressor.predict(dim_reducer.transform(X_test))\n",
    "print('Loss for Elastic Net: ', mean_squared_error(y_true=y_test, y_pred= y_pred, squared=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ln46mTMYLxHx"
   },
   "source": [
    "### In order to find a better model, we're going to build the second model: Random Forest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "F6ElCETTNDKM",
    "outputId": "d8a719b6-22d7-4264-96bb-6fbd835d9a60"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor()"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_regressor = RandomForestRegressor()\n",
    "rf_regressor.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8BlMBcIWNgFm",
    "outputId": "5e9b25c0-9def-494f-e62c-a0995417cafd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Loss :  2.5574455587682112\n"
     ]
    }
   ],
   "source": [
    "y_predict = rf_regressor.predict(dim_reducer.transform(X_test))\n",
    "\n",
    "print('Random Forest Loss : ', mean_squared_error(y_true=y_test, y_pred= y_predict, squared=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fiXGS-YpF1Ps",
    "outputId": "bd592bb4-1582-4cf0-f0bf-6b070177abc7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.44711348,  -8.50201752,  -7.26920903,  -7.60144478,\n",
       "        -7.70576487, -11.47864141])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### From the result above, obviously we see that Random Forest model is better than Linear Regression\n",
    "\n",
    "from sklearn.model_selection import cross_val_score as cvs\n",
    "##Applying the Cross Validation to test whether the Randon Forest's performance is good over all the data\n",
    "\n",
    "score_lr = cvs(estimator=lr_regressor,X=dim_reducer.transform(X),y=y,scoring='neg_root_mean_squared_error',cv=6, n_jobs=-1)\n",
    "score_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9WnfEFReJ1yG",
    "outputId": "ecb4def2-4b72-453e-e609-99d7882e5986"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-12.52667616, -17.71926564, -15.40745063, -15.77689074,\n",
       "       -11.24637719, -20.69484177])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rf = cvs(estimator=rf_regressor,X=dim_reducer.transform(X),y=y,scoring='neg_root_mean_squared_error',cv=6, n_jobs=-1)\n",
    "score_rf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LIxGcmxbKCwO",
    "outputId": "858f8474-8af8-4e4b-a670-85f4545d0e0c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -5.51396016,  -9.50185444,  -8.07288254,  -8.21705023,\n",
       "        -7.55161405, -12.77093067])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_rl = cvs(estimator=elastic_net_regressor,X=dim_reducer.transform(X),y=y,scoring='neg_root_mean_squared_error',cv=6, n_jobs=-1)\n",
    "score_rl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NDu0yUEYK_ek",
    "outputId": "abc88268-afb8-4a16-ecfa-3a84c118a9ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "negative MSE Linear Regression( mean: -8.00076965570607 std:1.8097084983140221)\n",
      "negative MSE Random Forest Regression( mean: -15.321181684691794 std:2.993054415727865)\n",
      "negative MSE Elastic Net( mean: -8.60471534714482 std:2.2082092677610676)\n"
     ]
    }
   ],
   "source": [
    "print('negative MSE Linear Regression( mean: {} std:{})'.format(score_lr.mean(),score_lr.std()))\n",
    "print('negative MSE Random Forest Regression( mean: {} std:{})'.format(score_rf.mean(),score_rf.std()))\n",
    "print('negative MSE Elastic Net( mean: {} std:{})'.format(score_rl.mean(),score_rl.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GHMcs3HTYE9B"
   },
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Modeling.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
